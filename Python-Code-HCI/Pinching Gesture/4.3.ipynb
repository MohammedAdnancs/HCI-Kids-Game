{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "657236f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from dollarpy import Recognizer, Template, Point\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83140da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of video paths to train on the same gesture\n",
    "video_files = [\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 5.30.18 PM.mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 6.01.43 PM(5).mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 6.01.43 PM.mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-03 at 7.56.43 PM.mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 8.09.51 PM (1).mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 8.09.51 PM.mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 8.14.23 PM.mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\WhatsApp Video 2024-11-02 at 8.10.09 PM.mp4\",\n",
    "    r\"C:\\Users\\Youssef\\Desktop\\Test\\IMG_6642.mov\",\n",
    "    # Add more video paths as needed\n",
    "]\n",
    "\n",
    "def getPoints(video_files, pinch_gesture=False):\n",
    "    all_points = []\n",
    "    for videoURL in video_files:\n",
    "        cap = cv2.VideoCapture(videoURL)\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                results = holistic.process(image)\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                # If landmarks are detected, process pinching gestures\n",
    "                if results.right_hand_landmarks or results.left_hand_landmarks:\n",
    "                    try:\n",
    "                        hand_landmarks = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "                        index_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                        thumb_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "                        \n",
    "                        # Calculate distance between thumb and index fingertip to detect pinch\n",
    "                        distance = ((thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2) ** 0.5\n",
    "\n",
    "                        # If pinch detected, add relevant points to the gesture points list\n",
    "                        if pinch_gesture and distance < 0.05:  # Adjust threshold as needed\n",
    "                            all_points.append(Point(index_tip.x, index_tip.y, 1))  # Label for pinch gesture\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Display the frame\n",
    "                cv2.imshow(\"Gesture Training\", image)\n",
    "                \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return all_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3056b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to pinching.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train the model and create the template for the Circle Gesture\n",
    "all_points = getPoints(video_files, pinch_gesture=True)\n",
    "\n",
    "# Create a single template for the Circle Gesture\n",
    "circle_template = Template(\"Circle Gesture\", all_points)\n",
    "templates = [circle_template]\n",
    "\n",
    "# Initialize recognizer with the single gesture template\n",
    "recognizer = Recognizer(templates)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'pinching.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(templates, model_file)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434e5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n",
      "Not pinching\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Start real-time gesture detection\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mgetPointsRealTime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinching_status_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m, in \u001b[0;36mgetPointsRealTime\u001b[1;34m(pinching_detected_callback)\u001b[0m\n\u001b[0;32m     18\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     19\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     23\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def pinching_status_callback(pinching_detected):\n",
    "    if pinching_detected:\n",
    "        print(\"Pinching\")\n",
    "    else:\n",
    "        print(\"Not pinching\")\n",
    "\n",
    "def getPointsRealTime(pinching_detected_callback):\n",
    "    cap = cv2.VideoCapture(0)  # Use camera\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Flip the frame horizontally to mirror the camera feed\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            results = holistic.process(image)\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "            # Check for pinch gesture\n",
    "            pinching_detected = False\n",
    "            if results.right_hand_landmarks or results.left_hand_landmarks:\n",
    "                try:\n",
    "                    hand_landmarks = results.right_hand_landmarks or results.left_hand_landmarks\n",
    "                    index_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                    thumb_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "                    \n",
    "                    # Calculate distance between thumb and index fingertip to detect pinch\n",
    "                    distance = ((thumb_tip.x - index_tip.x)**2 + (thumb_tip.y - index_tip.y)**2) ** 0.5\n",
    "\n",
    "                    if distance < 0.02:  # Adjust threshold as needed\n",
    "                        pinching_detected = True\n",
    "                        # Draw a green dot at the pinch location\n",
    "                        pinch_x = int(index_tip.x * image.shape[1])\n",
    "                        pinch_y = int(index_tip.y * image.shape[0])\n",
    "                        cv2.circle(image, (pinch_x, pinch_y), 10, (0, 255, 0), -1)  # Draw green dot\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing hand landmarks: {e}\")\n",
    "\n",
    "            # Call the callback with the current pinching status\n",
    "            pinching_detected_callback(pinching_detected)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow(\"Gesture Detection\", image)\n",
    "            \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Start real-time gesture detection\n",
    "getPointsRealTime(pinching_status_callback)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
